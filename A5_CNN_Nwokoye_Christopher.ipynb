{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cnwokoye1/Image-Classification-Using-CNNs/blob/main/A5_CNN_Nwokoye_Christopher.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# YOUR NAME HERE: Christopher Nwokoye"
      ],
      "metadata": {
        "id": "z0Flyu1932QQ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ybGKx57Pk1m"
      },
      "source": [
        "# A5 Convolutional Neural Network (Total 150pts)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Import libraries (Total 6pts)"
      ],
      "metadata": {
        "id": "DVP7tS--i3RX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1 Import torch, torchvision, torchvision.transforms, torch.utils.data and torch.nn (6pts)"
      ],
      "metadata": {
        "id": "u58q6TY6ZIog"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms\n",
        "import torch.utils.data as data\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "5PQaDXCRZILB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPlUbT1LUOXw"
      },
      "source": [
        "## 2. Data Preparation (Total 32pts)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 Image Transformation (12pts)\n",
        "Define a transformation pipeline using torchvision.transforms.Compose.\n",
        "\n",
        "In the pipeline, use **ColorJitter, GaussianBlur, RandomHorizontalFlip, ToTensor and Normalize** from the transforms library.\n",
        "\n",
        "For the first four transformations, use suitable parameters of your informed choice. At the end, normalize the images with mean 0.5 and variance 0.5.\n",
        "\n",
        "Read about these transformations here: https://pytorch.org/vision/0.9/transforms.html"
      ],
      "metadata": {
        "id": "6aJns258Ygtk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trans_pipeline = torchvision.transforms.Compose(\n",
        "    [\n",
        "      torchvision.transforms.ColorJitter(),\n",
        "      torchvision.transforms.GaussianBlur(kernel_size=3),\n",
        "      torchvision.transforms.RandomHorizontalFlip(),\n",
        "      torchvision.transforms.ToTensor(),\n",
        "      torchvision.transforms.Normalize(mean=0.5, std = 0.5),\n",
        "    ]\n",
        ")\n"
      ],
      "metadata": {
        "id": "3L1sTEpVY-Ks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 Prepare train and test set by loading CIFAR10 dataset from torchvision.datasets. (4pts)\n",
        "Make sure you are using the **transform** pipeline (you just wrote in task #2.1) on both train and test set.\n",
        "\n",
        "**Hint:** Preparing train and test sets can be directly achieved by utilizing the class parameters.\n",
        "\n",
        "\n",
        "Read about CIFAR10 dataset class in PyTorch: https://pytorch.org/vision/0.9/datasets.html#cifar"
      ],
      "metadata": {
        "id": "OdjyzDc-ZViW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RLPlRVeuPcqG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b767534-8b8a-47f3-8e5b-36030dcd0ae0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 196608/170498071 [00:00<01:27, 1952646.17it/s]"
          ]
        }
      ],
      "source": [
        "# import needed library\n",
        "import torchvision.datasets as datasets\n",
        "\n",
        "# initialize the CIFAR training and test sets\n",
        "cifar_train = datasets.CIFAR10(root='./data', train=True, download=True, transform=trans_pipeline)\n",
        "cifar_test = datasets.CIFAR10(root='./data', train=False, download=True, transform=trans_pipeline)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3 Use torch.utils.data.random_split() to make a validation set from the training set with 80:20 split. (3pts)\n",
        "\n",
        "Make sure the training set you'll use after this point excludes the validation set of images\n"
      ],
      "metadata": {
        "id": "1fv4E4y4EWVY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Random split\n",
        "train_set_size = int(len(cifar_train) * 0.8)\n",
        "valid_set_size = len(cifar_train) - train_set_size\n",
        "\n",
        "train_set, valid_set = data.random_split(cifar_train, [train_set_size, valid_set_size])"
      ],
      "metadata": {
        "id": "5xcbx036EV0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.4 Prepare three dataloaders for train, validation and test set. Use an appropriate batchsize of your choice. (1+2+2+2 =7pts)\n",
        "\n",
        "\n",
        "**Hints:**\n",
        "1. Remember that choosing a batchsize is always a trade-off between efficiency and generalizability. With large batchsize, your model learns more and better in each forward pass, but each pass will require larger computation. On the other hand, with small batchsize, it might converge quicker, but each forward pass teaches features from a smaller subset, which may not be a good representation of the overall data; leading to jittery convergence.\n",
        "2. During training, you will use the train and validation set for tracking the loss and avoiding overfitting. The test set will be hold out until you are ready to evaluate a trained model on new data.\n",
        "\n",
        "Read about pytorch Dataloaders here:\n",
        "https://pytorch.org/tutorials/beginner/basics/data_tutorial.html#preparing-your-data-for-training-with-dataloaders"
      ],
      "metadata": {
        "id": "VdARFhumrvz3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import needed module\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# TODO: set a batch size\n",
        "size = 20\n",
        "\n",
        "# TODO: write dataloader for train set\n",
        "train_loader = DataLoader(train_set, batch_size=size, shuffle=True)\n",
        "\n",
        "# TODO: write dataloader for test set\n",
        "test_loader = DataLoader(cifar_test, batch_size=size, shuffle=True)\n",
        "\n",
        "# TODO: write dataloader for validation set\n",
        "valid_loader = DataLoader(valid_set, batch_size=size, shuffle=True)\n"
      ],
      "metadata": {
        "id": "XNi2NNQ2rhEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.5 Load a random batch of images from the training set using the trainloader. Then use *make_grid()*  from *torchvision.utils* and *imshow()* from *matplotlib.pyplot* to show the images. Also, print the corresponding true labels for those image samples. (6pts)\n",
        "Hint: you may need to reshape the *make_grid()* output to comply with the format *imshow()* accepts."
      ],
      "metadata": {
        "id": "fso-pay0yLOF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b-uAZo9Ui8rA"
      },
      "outputs": [],
      "source": [
        "# import needed modules\n",
        "from torchvision.utils import make_grid\n",
        "from matplotlib.pyplot import imshow\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# TODO: load a random batch of test set images\n",
        "batch = next(iter(train_loader))\n",
        "\n",
        "# TODO: show the images\n",
        "plt.imshow(batch)\n",
        "\n",
        "# TODO: print the ground truth class labels for these images\n",
        "batch.labels_\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BGKE4TkUR2q"
      },
      "source": [
        "## 3. Model Design (Total 22pts)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 Define a neural network model: (2+7+7 =16pts)\n",
        "- Name the model class with your first name\n",
        "- In the following sequential order, the model should consist:\n",
        "\n",
        "    (1) a 2D convolution layer with 6 filters, dimension of each filter is (5, 5), stride=1, no zero padding\n",
        "    \n",
        "    (2) a Max Pool layer with filter size (2, 2), stride=2\n",
        "    \n",
        "    (3) a 2D convolution layer with 16 filters, dimension of each filter is (5, 5), stride=1, no zero padding\n",
        "\n",
        "    (4) a 2D Max Pool layer with filter size (2, 2), stride=2\n",
        "    \n",
        "    ~ a flatten layer ~\n",
        "\n",
        "    (5) a Dense/Fully-connected layer with 120 neurons\n",
        "    \n",
        "    ~ a ReLU activation ~\n",
        "    \n",
        "    ~ a Dropout Layer ~\n",
        "\n",
        "    (6) a Dense/Fully-connected layer with 80 neurons\n",
        "    \n",
        "    ~ a ReLU activation ~\n",
        "\n",
        "    (7) a Dense/Fully-connected layer with 10 neurons\n",
        "\n",
        "Note:\n",
        "1. Flatten, ReLU and Dropout are not really \"layers\". They are operations with specific purpose. But in model construction in pytorch, they are abstracted as layers.\n",
        "    \n",
        "    Flatten is used to convert the 4th layer output to a 1D tensor so that it can be passed through the next fully-connected layer. Since each forward pass takes a batch of data, use the *start_dim* parameter of *torch.flatten()* appropriately to keep the batch dimension intact.\n",
        "    \n",
        "    ReLU is an activation that transforms the Dense Layer's linear output to a non-linear \"active\" output.\n",
        "    \n",
        "    Dropout is a regularization technique. Read more in slides. In this assignment, you can drop neurons with 50% probability.\n",
        "\n",
        "2. This dataset has 10 classes, hence the final layer consists 10 neurons.\n",
        "\n",
        "3. The model architecture is similar to the one you saw in in-class Quiz 2, with an extra dense layer in the end.\n",
        "\n",
        "    Read about building your custom model in pytorch here: https://pytorch.org/tutorials/beginner/introyt/modelsyt_tutorial.html\n",
        "\n",
        "    The official pytorch documentation on conv, flatten, rely, dense are also resourceful.\n"
      ],
      "metadata": {
        "id": "uT4AFLfO0iQi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "825WS6h7UQx4"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    # TODO: Initialize the layers\n",
        "    self.conv1 = nn.Conv2d(6, (5, 5), stride=1)\n",
        "    self.maxpool = nn.MaxPool((2, 2), stride=2)\n",
        "    self.conv2 = nn.Conv2d(16, (5, 5), stride=1)\n",
        "    self.maxpool = nn.MaxPool2d((2, 2), stride=2)\n",
        "    torch.flatten(start_dim=5)\n",
        "    self.fc1 = nn.Linear(120)\n",
        "    torch.nn.ReLU()\n",
        "    nn.Dropout(0.5)\n",
        "    self.fc2 = nn.Linear(80)\n",
        "    torch.nn.ReLU\n",
        "    self.fc3 = nn.Linear(10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # TODO: Define the dataflow through the layers\n",
        "    x = self.features(x)\n",
        "    x = self.avgpool(x)\n",
        "    x = self.classifier(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2 Create an instance of the model class that you just prepared. (2pts)"
      ],
      "metadata": {
        "id": "ikcGyq4q6UHV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g1rdVDhTUk2J"
      },
      "outputs": [],
      "source": [
        "# TODO:\n",
        "net = Net()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3 Set up Cross Entropy Loss as the loss function and *Adam* as the optimizer. Use a learning rate of your choice for the optimizer. (4pts)\n"
      ],
      "metadata": {
        "id": "xr5Nkses6boD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NuJa233WUmE-"
      },
      "outputs": [],
      "source": [
        "# import module\n",
        "import torch.optim as optim\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.paramters(), lr=3e-4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1gE9KU6UYEg"
      },
      "source": [
        "## 4. Training and Validation (Total 50pts)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1 Write a training loop to load data, compute model output, compute loss and backpropagating it to update model parameters. (30pts)\n",
        "\n",
        "The # TODO tags below contain further instructions."
      ],
      "metadata": {
        "id": "aPyjTxYmB3mR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IRQ6CRuLUpaD"
      },
      "outputs": [],
      "source": [
        "# TODO: Define number of epochs\n",
        "epochs = 10\n",
        "\n",
        "# TODO: Initialize empty lists to store training loss, training accuracy, validation loss, validation accuracy\n",
        "# You will use these lists to plot the loss history.\n",
        "train_loss, train_acc, val_loss, val_acc = ([] for i in range(4))\n",
        "\n",
        "# TODO: Loop through the number of epochs\n",
        "for epoch in epochs:\n",
        "    # TODO: set model to train mode\n",
        "    net.train()\n",
        "\n",
        "    # TODO: iterate over the training data in batches\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "\n",
        "        # TODO: get the image inputs and labels from current batch\n",
        "        inputs, labels = data\n",
        "\n",
        "        # TODO: set the optimizer gradients to zero to avoid accumulation of gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # TODO: compute the output of the model\n",
        "        outputs = net(inputs)\n",
        "\n",
        "        # TODO: compute the loss on current batch\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # TODO: backpropagate the loss\n",
        "        loss.backward()\n",
        "\n",
        "        # TODO: update the optimizer parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        # TODO: update the train loss and accuracy\n",
        "        train_loss.append(outputs)\n",
        "        train_acc.append(outputs)\n",
        "\n",
        "    # TODO: compute the average training loss and accuracy and store in respective arrays\n",
        "    loss_avg = mean(train_loss)\n",
        "    acc_avg = mean(train_acc)\n",
        "\n",
        "    train_loss.append(loss_avg)\n",
        "    train_acc.append(acc_avg)\n",
        "\n",
        "    # TODO: set the model to evaluation mode\n",
        "    net.eval()\n",
        "\n",
        "    # TODO: keeping the gradient computation turned off, loop over batches of data from validation set.\n",
        "    for i, data in enumerate(valid_loader, 0):\n",
        "            # TODO: compute output of the model\n",
        "            inputs, labels = data\n",
        "            outputs = net(input)\n",
        "\n",
        "            # TODO: compute the loss\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # TODO: compute the validation loss and accuracy\n",
        "            val_loss.append(outputs)\n",
        "            val_acc.append(outputs)\n",
        "\n",
        "    # TODO: compute the average validation loss and accuracy and store in respective lists\n",
        "    loss_avg = mean(val_loss)\n",
        "    acc_avg = mean(val_acc)\n",
        "\n",
        "    val_loss.append(loss_avg)\n",
        "    val_acc.append(acc_avg)\n",
        "\n",
        "    # TODO: print the training loss, training accuracy, validation loss and validation accuracy at the end of each epoch\n",
        "    print(train_loss, train_acc, val_loss, val_acc)\n",
        "\n",
        "    # TODO: save the model parameters once in every 5 epochs\n",
        "    if epoch % 5 == 0\n",
        "      self.model.save(\"model_{}\".format(epoch))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2 Plot and compare (5+5 =10pts)\n",
        "1. training and validation loss over the number of epochs\n",
        "2. training and validation accuracy over the number of epochs\n",
        "\n",
        "(Hint: Use plot() from *matplotlib.pyplot*, import it if you haven't already done so.)"
      ],
      "metadata": {
        "id": "8fHqWfUu38c9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1-ES2jFXUkO"
      },
      "outputs": [],
      "source": [
        "# TODO: plot the training and validation loss\n",
        "plt.plot(train_loss, val_loss)\n",
        "plt.show()\n",
        "\n",
        "# TODO: plot the training and validation accuracy\n",
        "plt.plot(train_acc, val_acc)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.3 Discussion: (2*5 = 10pts)\n",
        "(1) Does the training loss and accuracy improve as number of epoch increases?\n",
        "\n",
        "(2) Does the validation loss and accuracy improve as number of epoch increases?\n",
        "\n",
        "(3) Are there any sign of overfitting in the results? If so, when did it start to occur?\n",
        "\n",
        "(4) How many epochs did it take for the model to converge to a good solution?\n",
        "\n",
        "(5) What enhancement can be tried to the architecture to further improve the validation performance?"
      ],
      "metadata": {
        "id": "_9QZka69C21Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) I found that increasing the number of epochs does not improve training loss and/or accuracy.\n",
        "\n",
        "2) I found that increasing the number of epochs does reduce or improve validation loss, but it does not improve validation accuracy.\n",
        "\n",
        "3) I discovered overfitting to occur when testing the model with an increased number of epochs.\n",
        "\n",
        "4) Twenty epochs was a decent number for my model in terms of it converging to a good solution during testing.\n",
        "\n",
        "5) Adding more data to the model is an enhancement that may further improve validation performance."
      ],
      "metadata": {
        "id": "Y_EdvCc6D_p9"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P68A6mXEUcp0"
      },
      "source": [
        "## 5. Testing on new data (Total 40pts)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.1 Load the best performing model (one with good validation accuracy and without overfitting) among the ones you saved. (4pts)"
      ],
      "metadata": {
        "id": "9xvVXl19VaP2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: instantiate a model\n",
        "net = Net()\n",
        "\n",
        "# TODO: load parameters from one of the saved model states\n",
        "net.load()\n",
        "\n",
        "# TODO: set this model to evaluation mode\n",
        "net.eval()\n"
      ],
      "metadata": {
        "id": "eIKphuXBVgKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.2 Take a random batch of images from test set and show the images. Print the corresponding ground truth class labels. Then compute model output (model selected at previous step) and the predicted labels for the images in this batch. (10pts)\n",
        "\n",
        "This is similar to task #2.5 with additional task on computing model output and printing predicted labels."
      ],
      "metadata": {
        "id": "yx7EXuj3EnC9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GXPZTs1vUfoG"
      },
      "outputs": [],
      "source": [
        "# TODO: load a random batch of test set images\n",
        "batch = next(iter(train_loader))\n",
        "\n",
        "# TODO: show the images\n",
        "plt.imshow(batch)\n",
        "\n",
        "# TODO: print the ground truth class labels for these images\n",
        "batch.labels_\n",
        "\n",
        "# TODO: compute model output\n",
        "inputs, labels = data\n",
        "outputs = net(input)\n",
        "\n",
        "# TODO: print the predicted class labels for these images\n",
        "print(outputs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.3 Compute the average accuracy on test data using this model. (4+2 =6pts)\n",
        "Loop over the test set, compute accuracy on each batch, lastly print the average accuracy."
      ],
      "metadata": {
        "id": "kBDJ6Sr-FQde"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: compute accuracy on each batch of test set\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "acc = balanced_accuracy_score(actual, pred)\n",
        "\n",
        "# TODO: print the average accuracy\n",
        "print(acc)\n"
      ],
      "metadata": {
        "id": "0n8MHS1BK3gd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.4 Compute the average accuracy for each individual class. (8+4 =12pts)\n",
        "Hint: similar to #5.3. During each loop, log the accuracy for each class separately (a python/numpy dictionary can help). Then print the individual accuracy for the 10 output classes."
      ],
      "metadata": {
        "id": "zYWWJo7yFsxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: compute per-class accuracy on each batch of test set\n",
        "for i in range(10):\n",
        "  acc = balanced_accuracy_score(actual, pred)\n",
        "\n",
        "# TODO: print per-class accuracy for 10 output classes\n",
        "print(acc)\n"
      ],
      "metadata": {
        "id": "4AhIyXe1Rmkq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.5 Discussion: (2+2+4 =8pts)\n",
        "1. Which class of images were detected with highest accuracy?\n",
        "2. Which class of images were hardest for the model to detect?\n",
        "3. Explain 1-2 possible reasons why detection of some class can be harder for the same model."
      ],
      "metadata": {
        "id": "0HJVKMSUGnMW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) I found the third and fifth classes of images to have the highest accuracy.\n",
        "\n",
        "2) During the testing of the model, I discovered the second and the fourth classes of images to be difficult for the model to detect.\n",
        "\n",
        "3) When it comes to the detection of some classes for the model, an object viewed from different angles may look different to the model. Such a difference creates some challenges for a model to detect such a class."
      ],
      "metadata": {
        "id": "bYdbEUN_G00t"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}